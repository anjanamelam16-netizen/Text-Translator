{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import torch.nn.functional as F\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from torch.nn.functional import one_hot\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "3JRt9DgoIzVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install indic-nlp-library\n",
        "from indicnlp.tokenize import indic_tokenize"
      ],
      "metadata": {
        "id": "VdlFMPLCajZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language1_filepath = \"\"\n",
        "language2_filepath = \"\"\n",
        "lang1 = \"english\"\n",
        "lang2 = \"hindi\"\n",
        "\n",
        "with open(language1_filepath, \"r\", encoding='utf-8') as f:\n",
        "  language1_data = f.readlines()\n",
        "\n",
        "with open(language2_filepath, \"r\", encoding='utf-8') as f:\n",
        "  language2_data = f.readlines()"
      ],
      "metadata": {
        "id": "SYiAWp0p7CHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "req_language1 = language1_data[242929:267939]\n",
        "req_language2 = language2_data[242929:267939]\n",
        "data = {\"language1_txt\":req_language1,\"language2_txt\":req_language2}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "vHq9uIt47tMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_language_corrupted(text):\n",
        "    if re.search(r'[^\\u0900-\\u097F\\s,.?!-]', text):\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "CLMBsn9M_Bo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning up text with is_language_corrupted(text)\n",
        "# Un-comment below if using Hindi or code changed for the language you are using\n",
        "\n",
        "# df['Corrupted'] = df['language2_txt'].apply(is_language_corrupted)\n",
        "# df_clean = df[~df['Corrupted']]\n",
        "# df_clean = df_clean.drop(columns=['Corrupted'])"
      ],
      "metadata": {
        "id": "IzYiEZRnHg0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text, language=\"english\"):\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "    if language == \"english\":\n",
        "        text = text.lower()\n",
        "    if language == \"hindi\":\n",
        "        text = re.sub('[a-zA-Z]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "-kq-NSH9yvuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean[\"language1_txt\"] = df_clean[\"language1_txt\"].apply(clean_text, args=(lang1,))\n",
        "df_clean[\"language2_txt\"] = df_clean['language2_txt'].apply(clean_text, args=(lang2,))"
      ],
      "metadata": {
        "id": "h-uvkUye8g8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean['language1_Words'] = df_clean['language1_txt'].apply(lambda x: len(x.split()))\n",
        "df_clean['language2_Words'] = df_clean['language2_txt'].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "5-j5YrNJLxid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_language1_words = df_clean['language1_Words'].quantile(.99)\n",
        "average_language2_words = df_clean['language2_Words'].quantile(.99)\n",
        "averages = [average_language1_words, average_language2_words]\n",
        "languages = ['language1', 'language2']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(languages, averages, color=['blue', 'red'])\n",
        "plt.xlabel('Language')\n",
        "plt.ylabel('Number of Words per Sentence')\n",
        "plt.title('Comparison of Number of Words Counts in language1 and language2')\n",
        "plt.ylim(0, max(averages) + 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NpOd55hIL7DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_language1 = get_tokenizer('basic_english')\n",
        "tokenizer_language2 = indic_tokenize.trivial_tokenize\n",
        "\n",
        "tokenized_language1_txt = [tokenizer_language1(language1_sen) for language1_sen in df_clean['language1_txt'] ]\n",
        "tokenized_language2_txt = [tokenizer_language2(language2_sen) for language2_sen in df_clean['language2_txt'] ]"
      ],
      "metadata": {
        "id": "SzBeCo8MOcwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_language1_txt, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "target_vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_language2_txt, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "\n",
        "features_vocab.set_default_index(features_vocab['<unk>'])\n",
        "target_vocab.set_default_index(target_vocab['<unk>'])"
      ],
      "metadata": {
        "id": "upBTp-UJS9xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_vocab_total_words = len(features_vocab)\n",
        "target_vocab_total_words = len(target_vocab)"
      ],
      "metadata": {
        "id": "CkkIj_XFLjWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_indices(tokenized_texts, vocab):\n",
        "    indices_texts = []\n",
        "    for sentence in tokenized_texts:\n",
        "        indices_texts.append([vocab[token] for token in sentence if token in vocab])\n",
        "    return indices_texts"
      ],
      "metadata": {
        "id": "uvUtpWeDLt_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language1_indices = tokens_to_indices(tokenized_language1_txt, features_vocab)\n",
        "language2_indices = tokens_to_indices(tokenized_language2_txt, target_vocab)"
      ],
      "metadata": {
        "id": "t1pH9g5XM-Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, language1_data, language2_data):\n",
        "        self.language1_data = language1_data\n",
        "        self.language2_data = language2_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.language1_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        language1 = torch.tensor(self.language1_data[idx], dtype=torch.long)\n",
        "        language2 = torch.tensor(self.language2_data[idx], dtype=torch.long)\n",
        "        return language1, language2\n",
        "\n",
        "dataset = TranslationDataset(language1_indices, language2_indices)\n",
        "FIXED_LENGTH = 60\n"
      ],
      "metadata": {
        "id": "Ohf0O1CnM-Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    language1_batch, language2_batch = zip(*batch)\n",
        "\n",
        "    language1_batch = [torch.tensor(seq[:FIXED_LENGTH], dtype=torch.long) if len(seq) > FIXED_LENGTH else torch.cat([torch.tensor(seq, dtype=torch.long), torch.full((FIXED_LENGTH - len(seq),), features_vocab['<pad>'], dtype=torch.long)]) for seq in language1_batch]\n",
        "    language2_batch = [torch.tensor(seq[:FIXED_LENGTH], dtype=torch.long) if len(seq) > FIXED_LENGTH else torch.cat([torch.tensor(seq, dtype=torch.long), torch.full((FIXED_LENGTH - len(seq),), target_vocab['<pad>'], dtype=torch.long)]) for seq in language2_batch]\n",
        "\n",
        "    language1_batch = torch.stack(language1_batch)\n",
        "    language2_batch = torch.stack(language2_batch)\n",
        "    return language1_batch, language2_batch"
      ],
      "metadata": {
        "id": "KBEn7e-NcxkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_batch, shuffle=True)"
      ],
      "metadata": {
        "id": "TDhltO-xc1zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "bs67MOd8achu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "aUv5MU5RM-UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        key_shape = keys.size()\n",
        "\n",
        "        query = query.repeat(1, key_shape[1], 1)\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(-1)\n",
        "\n",
        "        weights = torch.softmax(scores, dim=1)\n",
        "        weights = weights.unsqueeze(1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "\n",
        "        bos_token_index = features_vocab['<bos>']\n",
        "        decoder_input = torch.full((batch_size, 1), bos_token_index, dtype=torch.long, device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(60):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "            else:\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "SOZQffs_aOrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "I53ihZ7Jfiab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=5, plot_every=5, save_every=5, save_path=''):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "        if epoch % save_every == 0:\n",
        "            encoder_save_path = os.path.join(save_path, '')\n",
        "            decoder_save_path = os.path.join(save_path, '')\n",
        "            torch.save(encoder.state_dict(), encoder_save_path)\n",
        "            torch.save(decoder.state_dict(), decoder_save_path)\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "uHBcirVDfidT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "rzuTOQJ8ffI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "        input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "E96KOEbPfW1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "features_vocab_total_words = len(features_vocab)\n",
        "target_vocab_total_words = len(target_vocab)\n",
        "\n",
        "encoder = EncoderRNN(features_vocab_total_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, target_vocab_total_words).to(device)"
      ],
      "metadata": {
        "id": "E3J8fUnzfiHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataloader, encoder, decoder, n_epochs = 50, print_every=5, plot_every=5)"
      ],
      "metadata": {
        "id": "kNAVKmc3jxWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.load_state_dict(torch.load(\"\"))\n",
        "decoder.load_state_dict(torch.load(\"\"))"
      ],
      "metadata": {
        "id": "zTqoulmIj1Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, feature_vocab, target_vocab):\n",
        "    with torch.no_grad():\n",
        "\n",
        "        tokenized_language1_txt_test = tokenizer_language1(sentence)\n",
        "        language1_indices_test = tokens_to_indices(tokenized_language1_txt_test, features_vocab)\n",
        "        input_tensor = torch.LongTensor(language1_indices_test).to(device).reshape(1,4)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        EOS_token = feature_vocab['<eos>']\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<eos>')\n",
        "                break\n",
        "            decoded_words.append(target_vocab.get_itos()[idx] if idx < len(target_vocab) else '<unk>')\n",
        "    return decoded_words, decoder_attn"
      ],
      "metadata": {
        "id": "RBihHux53ta0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"\"\n",
        "decoder_output, attn_weights = evaluate(encoder, decoder, sentence, features_vocab, target_vocab)"
      ],
      "metadata": {
        "id": "ULRF2SUm3rGT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}